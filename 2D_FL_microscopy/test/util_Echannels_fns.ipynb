{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import dxchange\n",
    "from scipy.ndimage import rotate as sp_rotate\n",
    "import xraylib_np as xlib_np\n",
    "import xraydb as xdb\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attenuation(src_path, n_theta, theta_ls, sample_size, sample_size_l, element_ls, an_lib):\n",
    "    \"\"\"\n",
    "    Calculate the attenuation ratio of the incident beam before the beam travels to a certain voxel\n",
    "    Assuming that the x-ray probe goes along the direction of axis=1 of the sample array\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    theta_ls: ndarray\n",
    "        The angles that the sample rotates from the initial angle in the experiment\n",
    "    \n",
    "    sample_size: int scalar\n",
    "        sample size in number of pixles on one side, assuing a N x N-pixel sample\n",
    "    \n",
    "    sample_size_l: scalar\n",
    "        sample size in mm\n",
    "    \n",
    "    element_ls: ndarray\n",
    "        elements in the sample\n",
    "        \n",
    "    Returns: ndarray\n",
    "    -------\n",
    "        dimension of the returned array is n_theta x sample_size x sample_size\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    an_ls = np.array(list(an_lib.values()))\n",
    "    probe_energy = np.array([20.0])\n",
    "\n",
    "    ## genrate the library of the total attenuation cross section for the involved elements at 20 keV\n",
    "    cs_probe_ls = xlib_np.CS_Total(an_ls, probe_energy).flatten()\n",
    "    cs_probe_lib = dict(zip(element_ls, cs_probe_ls))\n",
    "    \n",
    "    att_acc_map = np.zeros((n_theta, sample_size, sample_size))\n",
    "    for i, theta in enumerate(theta_ls):\n",
    "        for j, element in enumerate(element_ls):\n",
    "            concentration_map_fname = os.path.join(src_path, element + '_map.tiff')\n",
    "            concentration_map = dxchange.reader.read_tiff(concentration_map_fname)\n",
    "            concentration_map_rot = sp_rotate(concentration_map, theta, reshape=False, order=1)\n",
    "            lac_single = concentration_map_rot * cs_probe_lib[element]            \n",
    "            lac_acc = np.cumsum(lac_single, axis=1)  \n",
    "            lac_acc = np.insert(lac_acc, 0, np.zeros(sample_size), axis=1)\n",
    "            lac_acc = np.delete(lac_acc, sample_size, axis=1)\n",
    "            att_acc = lac_acc * (sample_size_l / sample_size)\n",
    "            att_acc_map[i,:,:] += att_acc\n",
    "    return np.exp(-att_acc_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trace_beam_yint(x1, y1, xd, yd, sample_x_edge):\n",
    "    m = (yd - y1)/(xd - x1)\n",
    "    y_int = m * (sample_x_edge - x1) + y1\n",
    "    return m, y_int\n",
    "\n",
    "def trace_beam_xint(x1, y1, xd, yd, sample_y_edge):\n",
    "    if yd == y1:\n",
    "        m = 0\n",
    "        x_int = np.array([])\n",
    "    else:\n",
    "        m = (yd - y1)/(xd - x1)\n",
    "        x_int = (sample_y_edge - y1)/m + x1\n",
    "    return m, x_int\n",
    "\n",
    "def intersecting_length_fl_detectorlet(n_det, sample_size, sample_size_l, det_pos_ls):\n",
    "    voxel_size = sample_size_l / sample_size\n",
    "    ## define index position of center of the source voxel (x1, y1), note that it's shifted by 0.5 to represent the center\n",
    "    x1, y1 = np.indices((sample_size, sample_size))\n",
    "    x1, y1 = x1 + 0.5, y1 + 0.5\n",
    "    voxel_pos_ls = np.dstack((x1, y1))\n",
    "\n",
    "    ## define sample edges: \n",
    "    ## sample_x_edge is the edge that is closer to the XRF detector\n",
    "    ## sample_y_edge has two components representing the left and the right edge\n",
    "    sample_x_edge = sample_size\n",
    "    sample_y_edge = np.array([0, sample_size])\n",
    "\n",
    "\n",
    "    ## make voxel_pos_ls 1D array for looping: voxel_pos_ls_flat\n",
    "    voxel_pos_ls_flat =  np.reshape(voxel_pos_ls, (1, voxel_pos_ls.shape[0]*voxel_pos_ls.shape[0], 2))[0]\n",
    "\n",
    "    P = np.zeros((n_det, sample_size * sample_size, sample_size * sample_size))\n",
    "    for i, det_pos in enumerate(det_pos_ls):\n",
    "        for j, v in enumerate(voxel_pos_ls_flat):\n",
    "            # find x-value when the beam enters the sample WITHOUT intersecting the sample_y_edges(left & right), namely the beam is parallel with the y edge of the sample. \n",
    "            # find x-value when the beam passes through sample_y_edges(left & right), the one with larger x is the intersection with lower edge\n",
    "            if v[1] == det_pos[1]:\n",
    "                xint = sample_size\n",
    "            else:\n",
    "                xint = np.max(trace_beam_xint(v[0], v[1], det_pos[0], det_pos[1], sample_y_edge)[1])\n",
    "            xint_sample = np.clip(xint, 0, sample_size)\n",
    "        \n",
    "            # find y-value when the beam passes through sample_x_edge(bottom)\n",
    "            m = trace_beam_yint(v[0], v[1], det_pos[0], det_pos[1], sample_x_edge)[0]\n",
    "            yint = trace_beam_yint(v[0], v[1], det_pos[0], det_pos[1], sample_x_edge)[1]\n",
    "            yint_sample = np.clip(yint, 0, sample_size)\n",
    "    \n",
    "               \n",
    "            # when the beam enters a voxel, it either intersects the x boundary or y boundary of the voxel\n",
    "            # find the x,y-value of the boundary except the ones on the sample edge\n",
    "            if np.floor(xint_sample) != np.floor(v[0]):\n",
    "                x_edge_ls = np.linspace(np.ceil(xint_sample)-1, np.ceil(v[0]), int(np.abs(np.ceil(xint_sample) - np.ceil(v[0]))))\n",
    "            else: \n",
    "                x_edge_ls = np.array([])\n",
    "            \n",
    "        \n",
    "            if np.floor(yint_sample) != np.floor(v[1]):            \n",
    "                if m < 0:\n",
    "                    y_edge_ls = np.linspace(np.floor(yint_sample)+1, np.floor(v[1]), int(np.abs(np.floor(yint_sample)+1 - np.floor(v[1]))) + 1)            \n",
    "           \n",
    "                if m > 0:\n",
    "                    y_edge_ls = np.linspace(np.ceil(yint_sample)-1, np.ceil(v[1]), int(np.abs(np.ceil(yint_sample) - np.ceil(v[1]))))\n",
    "            else:\n",
    "                y_edge_ls = np.array([])\n",
    "        \n",
    "        \n",
    "            # find all intersections (except the initial intersection): \n",
    "            # 1. find y-value of intersection given x_edge_ls\n",
    "            # 2. find x-value of intersection given y_edge_ls\n",
    "            y_int_x_edge_ls = trace_beam_yint(v[0], v[1], det_pos[0], det_pos[1], x_edge_ls)[1] #solve y intersections given x edge\n",
    "            x_int_y_edge_ls = trace_beam_xint(v[0], v[1], det_pos[0], det_pos[1], y_edge_ls)[1] #solve x intersections given y edge\n",
    "        \n",
    "            # compile the x,y coordinates of the intersection: (x,y) = (x_edge_ls, y_int_x_edge_ls) and (x_int_y_edge_ls,y_edge_ls)\n",
    "            int_x_edge_ls = np.dstack((x_edge_ls,y_int_x_edge_ls))[0]\n",
    "            int_y_edge_ls = np.dstack((x_int_y_edge_ls,y_edge_ls))[0]\n",
    "\n",
    "            # sort them using the x coordinate\n",
    "            int_ls = np.concatenate((int_x_edge_ls, int_y_edge_ls))\n",
    "            int_ls = np.vstack((np.array([xint_sample, yint_sample]), int_ls))\n",
    "            int_ls = int_ls[np.argsort(int_ls[:,0])]\n",
    "        \n",
    "            # calculate the intersecting length in the intersecting voxels\n",
    "            int_length = np.sqrt(np.diff(int_ls[:,0])**2 + np.diff(int_ls[:,1])**2) \n",
    "            # just in case that we count some intersections twice, delete the duplicates\n",
    "            idx_duplicate = np.array(np.where(int_length==0)).flatten()\n",
    "            int_ls = np.delete(int_ls, idx_duplicate, 0)\n",
    "            int_length = np.delete(int_length, idx_duplicate) \n",
    "        \n",
    "            # determine the indices of the intersecting voxels according to the intersecting x,y-coordinates\n",
    "            int_ls_shift = np.zeros((int_ls.shape))\n",
    "            int_ls_shift[1:] = int_ls[:-1]\n",
    "            int_idx = np.floor((int_ls_shift + int_ls_shift)/2)[1:]        \n",
    "            int_idx = (int_idx[:,0].astype('int'), int_idx[:,1].astype('int'))\n",
    "        \n",
    "            # construct the int_length_map, and scale the intersecting length based on the voxel size\n",
    "            int_length_map = np.zeros((sample_size, sample_size))\n",
    "            int_length_map[int_idx] = int_length * voxel_size  \n",
    "         \n",
    "            P[i, j, :] = int_length_map.flatten()\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_absorption_ratio(src_path, sample_size, sample_size_l, n_theta, theta_ls, element_ls, att_cs_lib, n_det_energy_bins, n_det, det_pos_ls):\n",
    "    P = intersecting_length_fl_detectorlet(n_det, sample_size, sample_size_l, det_pos_ls)\n",
    "    SA = np.zeros((n_theta, sample_size * sample_size, n_det_energy_bins))\n",
    "    for i, theta in enumerate(tqdm(theta_ls.tolist(), leave=False)):\n",
    "        for j in np.arange(sample_size * sample_size):\n",
    "        \n",
    "            att_exponent_elemental_sum = np.zeros((len(element_ls), n_det, n_det_energy_bins))\n",
    "            for k, element in enumerate(element_ls):\n",
    "                concentration_map_fname = os.path.join(src_path, element + '_map.tiff')\n",
    "                concentration_map = dxchange.reader.read_tiff(concentration_map_fname)\n",
    "                concentration_map_rot = sp_rotate(concentration_map, theta, reshape=False, order=1)\n",
    "                ## flattened concentration_map after rotation (n_theta, sample_size * sample_size)\n",
    "                concentration_map_rot_flat = concentration_map_rot.flatten()\n",
    "            \n",
    "                ## linear attenuation coefficient for each energy at each voxel: (sample_size * sample_size, n_eneygy_bins)\n",
    "                lac = np.array([att_cs_lib[element] * concentration for concentration in concentration_map_rot_flat])\n",
    "            \n",
    "                ## att_exponent = [(intersecting_length_path1 * lac), (intersecting_length_path2 * lac), ..., (intersecting_length_path5 * lac)]:\n",
    "                ## att_exponent (for each energy, at each_voxel, for each beam path): (n_det, sample_size * sample_size, n_eneygy_bins)\n",
    "                att_exponent = np.array([P[m,j,:][:,np.newaxis] * lac for m in range(n_det)])\n",
    "            \n",
    "                ## att_exponent summing over voxels (for each energy, for each beam path): (n_det, n_eneygy_bins)\n",
    "                att_exponent_voxel_sum = np.sum(att_exponent, axis=1)\n",
    "\n",
    "                ## filling att_exponent_voxel_sum to att_exponent_elemental_sum for each element: (n_det, n_eneygy_bins)\n",
    "                att_exponent_elemental_sum[k, :, :] = att_exponent_voxel_sum\n",
    "        \n",
    "            ## summing over the attenation exponent contributed by each element: (n_det, n_eneygy_bins)\n",
    "            att_exponent_elemental_sum =  np.sum(att_exponent_elemental_sum, axis=0) \n",
    "                \n",
    "            ## calculate the attenuation caused by all elements\n",
    "            att = np.exp(- att_exponent_elemental_sum)\n",
    "            ## calculate the attenuation averaged all paths: dimension = n_energy_bins\n",
    "            att_path_ave = np.average(att, axis=0)\n",
    "            SA[i,j,:] = att_path_ave\n",
    "    return SA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest(a, a0):\n",
    "    \"Element in nd array `a` closest to the scalar value `a0`\"\n",
    "    idx = np.abs(a - a0).argmin()\n",
    "    return idx, a.flat[idx]\n",
    "\n",
    "## Returns fl cross section at each energy in det_energy_list per unit concentration of the element\n",
    "def MakeFLlinesDictionary(sample_size, sample_size_l, element_name, fl_lines_xdb, fl_lines, probe_energy, an_lib, det_energy_u, n_det_energy_bins):\n",
    "    voxel_size = sample_size_l / sample_size\n",
    "    FL_dic = {'element': element_name}\n",
    "    fl_cs_ls = xlib_np.CS_FluorLine_Kissel_Cascade(np.array([an_lib[element_name]]), fl_lines, probe_energy)\n",
    "    i = 0 \n",
    "    detected_fl_unit_concentration = np.zeros((n_det_energy_bins*2))\n",
    "    det_energy_list_full = np.linspace(- det_energy_u + det_energy_u / n_det_energy_bins, det_energy_u, n_det_energy_bins*2)\n",
    "    for name, line in xdb.xray_lines(element_name).items():\n",
    "        if name in set(fl_lines_xdb):\n",
    "            idx_nearest, value_nearest = find_nearest(det_energy_list_full, line[0])            \n",
    "            detected_fl_unit_concentration[idx_nearest] += fl_cs_ls[0,i][0]\n",
    "            i+=1\n",
    "    FL_dic['detected_fl_unit'] = detected_fl_unit_concentration * voxel_size\n",
    "    return FL_dic\n",
    "\n",
    "def Broadening_line(fl_unit, det_energy_list_full, sigma):\n",
    "    fl_unit_f = np.fft.fft(fl_unit)\n",
    "    b = (1/(np.sqrt(2*np.pi)*sigma))*np.exp(-(det_energy_list_full**2)/(2*sigma**2))\n",
    "    bf = np.fft.fft(b)\n",
    "    broadening_signal = np.fft.ifftshift(np.fft.ifft(fl_unit_f*bf))\n",
    "    \n",
    "    return np.real(broadening_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fl_signal_from_each_voxel(src_path, n_theta, theta_ls, sample_size, sample_size_l, element_ls, fl_lines_xdb, fl_lines, probe_energy, an_lib, det_energy_u, n_det_energy_bins, det_energy_list, sigma):\n",
    "    ## Calculate the FL signal emitted when shined by a incident beam with unit intensity\n",
    "    fl_map_tot = np.zeros((n_theta, sample_size * sample_size, n_det_energy_bins))\n",
    "    for i, theta in enumerate(theta_ls):\n",
    "        for j, element in enumerate(element_ls):\n",
    "            concentration_map_fname = os.path.join(src_path, element + '_map.tiff')\n",
    "            concentration_map = dxchange.reader.read_tiff(concentration_map_fname)\n",
    "            concentration_map_rot = sp_rotate(concentration_map, theta, reshape=False, order=1)\n",
    "            concentration_map_rot_flat = concentration_map_rot.flatten()\n",
    "        \n",
    "            ## FL signal emitted at unitary concentration of the current element over 2000 energy bins\n",
    "            fl_unit = MakeFLlinesDictionary(sample_size, sample_size_l, element, fl_lines_xdb, fl_lines, probe_energy, an_lib, det_energy_u, n_det_energy_bins)['detected_fl_unit']\n",
    "            ## Broaden FL signal based on the energy resolution of the detector\n",
    "            det_energy_list_full = np.linspace(- det_energy_u + det_energy_u / n_det_energy_bins, det_energy_u, n_det_energy_bins*2)\n",
    "            fl_unit_b = Broadening_line(fl_unit, det_energy_list_full, sigma)\n",
    "        \n",
    "            ## delete the negative part of the energy array\n",
    "            n_negative_energy = n_det_energy_bins\n",
    "            negative_energy_index_ls = np.arange(n_negative_energy).tolist()\n",
    "            fl_unit_b = np.delete(fl_unit_b, negative_energy_index_ls)\n",
    "        \n",
    "            ## FL signal over 2000 energy bins for each voxel\n",
    "            fl_map = np.array([fl_unit_b * concentration for concentration in concentration_map_rot_flat])\n",
    "            ## summing over the contribution from all elements\n",
    "            fl_map_tot[i,:,:] += fl_map\n",
    "    return  fl_map_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_XRF_data(n_theta, src_path, sample_size, sample_size_l, theta_ls, element_ls,  fl_lines_xdb, fl_lines, probe_energy,  an_lib, att_cs_lib, probe_intensity_1D, det_energy_u, n_det_energy_bins, det_energy_list, sigma, n_det, det_pos_ls):\n",
    "\n",
    "    ## create the profile of the probe\n",
    "    # create 1-D profile along axis 0, and then make it 2-D by copying the 1-D profile array along axis 1\n",
    "    probe_intensity_2D = probe_intensity_1D * np.ones((sample_size, sample_size))\n",
    "    # flatten the array: (400,)\n",
    "    probe_intensity_2D_flat = probe_intensity_2D.flatten()\n",
    "    # print(probe_intensity_2D_flat.shape)\n",
    "\n",
    "    ## create the array representing the ratio of remaining intensity after the attenuation along the incident direction of the probe\n",
    "    # flatten it: (n_theta, sample_size * sample_size)\n",
    "    att_flat = attenuation(src_path, n_theta, theta_ls, sample_size, sample_size_l, element_ls, an_lib).reshape(n_theta, sample_size * sample_size)\n",
    "    # print(att_flat.shape)\n",
    "\n",
    "    ## Calculate the remaining intensity of the probe at each voxel at each sample angle\n",
    "    att_probe_flat = probe_intensity_2D_flat * att_flat\n",
    "    # print(att_probe_flat.shape)\n",
    "    # flatten the calculated results and reshape it into a 2-D array with length=1 along axis 1\n",
    "    att_probe_flat2 = att_probe_flat.flatten()\n",
    "    att_probe_flat2 = np.array(att_probe_flat2[:,np.newaxis])\n",
    "    # print(att_probe_flat2.shape)\n",
    "\n",
    "    ## Calculate the generated fluorescence signal based on the attenuated probe\n",
    "    # print(fl_map_tot.shape)\n",
    "    fl_map_tot = generate_fl_signal_from_each_voxel(src_path, n_theta, theta_ls, sample_size, sample_size_l, element_ls, fl_lines_xdb, fl_lines, probe_energy, an_lib, det_energy_u, n_det_energy_bins, det_energy_list, sigma)\n",
    "    fl_map_tot_flat = fl_map_tot.reshape(n_theta*sample_size*sample_size, n_det_energy_bins)\n",
    "    # print(fl_map_tot_flat.shape)\n",
    "    fl_signal_flat = att_probe_flat2 * fl_map_tot_flat\n",
    "\n",
    "    SA = self_absorption_ratio(src_path, sample_size, sample_size_l, n_theta, theta_ls, element_ls, att_cs_lib, n_det_energy_bins, n_det, det_pos_ls)\n",
    "    ## flatten self-absroption matrix\n",
    "    # print(SA.shape)\n",
    "    SA_flat = SA.reshape(n_theta*sample_size*sample_size, n_det_energy_bins)\n",
    "\n",
    "    ## Calculated the fluorescence signal collected by the detector after self-absorption\n",
    "    fl_signal_SA_flat = fl_signal_flat * SA_flat\n",
    "\n",
    "    fl_signal_SA = fl_signal_SA_flat.reshape(n_theta, sample_size, sample_size, n_det_energy_bins)\n",
    "\n",
    "    fl_signal_SA_beamlet = np.sum(fl_signal_SA, axis=2)\n",
    "\n",
    "    np.save('./data/XRF_sample1.npy', fl_signal_SA_beamlet)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_XRT_data(src_path, sample_size, sample_size_l, n_theta, theta_ls, element_ls, an_lib, probe_intensity_1D):\n",
    "\n",
    "    ## create the profile of the probe\n",
    "    # create 1-D profile along axis 0, and then make it 2-D by copying the 1-D profile array along axis 1\n",
    "    probe_intensity_2D = probe_intensity_1D * np.ones((sample_size, sample_size))\n",
    "    # flatten the array: (400,)\n",
    "    probe_intensity_2D_flat = probe_intensity_2D.flatten()\n",
    "    # print(probe_intensity_2D_flat.shape)\n",
    "\n",
    "    ## create the array representing the ratio of remaining intensity after the attenuation along the incident direction of the probe\n",
    "    # flatten it: (n_theta, sample_size * sample_size)\n",
    "    att_flat = attenuation(src_path, n_theta, theta_ls, sample_size, sample_size_l, element_ls, an_lib).reshape(n_theta, sample_size * sample_size)\n",
    "    # print(att_flat.shape)\n",
    "    \n",
    "    ## Calculate the remaining intensity of the probe at each voxel at each sample angle\n",
    "    att_probe_flat = probe_intensity_2D_flat * att_flat\n",
    "    \n",
    "    att_probe = att_probe_flat.reshape(n_theta, sample_size, sample_size)\n",
    "    # print(att_probe.shape)\n",
    "    # print(att_probe)\n",
    "\n",
    "    XRT = att_probe[:,:,-1]\n",
    "    # print(XRT.shape)\n",
    "    # print(XRT)\n",
    "    np.save('./data/XRT_sample1.npy', XRT)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xraylib_np as xlib_np\n",
    "import xraylib as xlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 6/12 [08:44<08:44, 87.39s/it]"
     ]
    }
   ],
   "source": [
    "theta_st = 0\n",
    "theta_end = 180\n",
    "n_theta = 12\n",
    "theta_ls = - np.linspace(theta_st, theta_end, n_theta)\n",
    "\n",
    "## Define sample size in number of pixles on one side, assuing a N x N-pixel sample\n",
    "sample_size = 20 \n",
    "## Define sample size in cm on one side\n",
    "sample_size_l = 0.01 \n",
    "\n",
    "src_path = '../data/sample1'\n",
    "## Define probe posision, the position is defined to pass through the center of the voxel\n",
    "prob_pos_ls = np.array([x for x in np.arange(sample_size)]) + 0.5\n",
    "\n",
    "element_ls = np.array([\"C\", \"O\", \"Si\", \"Ca\", \"Fe\"])  \n",
    "an_lib = {\"C\": 6, \"O\": 8, \"Si\": 14, \"Ca\": 20, \"Fe\": 26}\n",
    "an_ls = np.array(list(an_lib.values()))\n",
    "\n",
    "## genrate the library of the total attenuation cross section for the involved elements at 20 keV\n",
    "probe_energy = np.array([20.0])\n",
    "cs_probe_ls = xlib_np.CS_Total(an_ls, probe_energy).flatten()\n",
    "cs_probe_lib = dict(zip(element_ls, cs_probe_ls))\n",
    "\n",
    "aw_ls = xlib_np.AtomicWeight(an_ls)\n",
    "aw_lib = dict(zip(element_ls, aw_ls)) \n",
    "\n",
    "n_det = 5\n",
    "det_energy_u = 20.0E3\n",
    "n_det_energy_bins = 2000\n",
    "det_energy_list = np.linspace(det_energy_u / n_det_energy_bins, det_energy_u, n_det_energy_bins)\n",
    "\n",
    "## genrate the library of the total attenuation cross section for the involved elements from 0-20keV\n",
    "att_cs_ls = xlib_np.CS_Total(an_ls, det_energy_list)\n",
    "att_cs_lib = dict(zip(element_ls, att_cs_ls))\n",
    "\n",
    "## Calculate the size of the voxel (unit in mm) using the length of the sample edge divided by the number of the pixels \n",
    "voxel_size = sample_size_l / sample_size\n",
    "\n",
    "## distance of the XRF detector from the sample edge\n",
    "det_from_sample = 16\n",
    "\n",
    "## diameter of the XRF detector\n",
    "det_size_l = 2.4\n",
    "det_size = np.ceil(det_size_l/voxel_size)\n",
    "\n",
    "## number of the detectorlets\n",
    "n_det = 5\n",
    "\n",
    "## x index of the location of the XRF detector\n",
    "det_axis_0_pixel = sample_size + np.ceil(det_from_sample/voxel_size) + 0.5\n",
    "det_axis_0_pixel_ls = np.full(n_det, det_axis_0_pixel)\n",
    "\n",
    "## y index of the location of the XRF detector\n",
    "det_axis_1_pixel_ls = np.linspace(np.ceil(sample_size/2) - det_size, \n",
    "                                  np.ceil(sample_size/2) + det_size, n_det) + 0.5\n",
    "\n",
    "## biding x-index and y-index array into [(x1,y1), (x2,y2), ..., (x_Ndet, y_Ndet)]\n",
    "det_pos_ls = np.array(list(zip(det_axis_0_pixel_ls, det_axis_1_pixel_ls)))\n",
    "\n",
    "fl_lines_xdb = np.array(['Ka2', 'Ka1', 'Kb1', 'Lb1', 'La2', 'La1'])\n",
    "fl_lines = np.array([xlib.KA2_LINE, xlib.KA1_LINE, xlib.KB1_LINE, xlib.LB1_LINE, xlib.LA2_LINE, xlib.LA1_LINE])\n",
    "\n",
    "sigma = 100 ## eV\n",
    "\n",
    "\n",
    "src_path = '../data/sample1'\n",
    "probe_intensity_1D = np.ones((sample_size, 1))\n",
    "create_XRF_data(n_theta, src_path, sample_size, sample_size_l, theta_ls, element_ls, fl_lines_xdb, fl_lines, probe_energy, an_lib, att_cs_lib, probe_intensity_1D, det_energy_u, n_det_energy_bins, det_energy_list, sigma, n_det, det_pos_ls)\n",
    "create_XRT_data(src_path, sample_size, sample_size_l, n_theta, theta_ls, element_ls, an_lib, probe_intensity_1D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
