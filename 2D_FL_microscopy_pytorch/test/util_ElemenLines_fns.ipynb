{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import dxchange\n",
    "from tqdm import tqdm\n",
    "from scipy.ndimage import rotate as sp_rotate\n",
    "import xraylib as xlib\n",
    "import xraylib_np as xlib_np\n",
    "from functools import partial \n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "element_list = np.array([\"H\", \"He\",\n",
    "                         \"Li\", \"Be\", \"B\", \"C\", \"N\", \"O\", \"F\", \"Ne\",\n",
    "                         \"Na\", \"Mg\", \"Al\", \"Si\", \"P\", \"S\", \"Cl\", \"Ar\",\n",
    "                         \"K\", \"Ca\", \"Sc\", \"Ti\", \"V\", \"Cr\", \"Mn\", \"Fe\", \"Co\", \"Ni\", \"Cu\", \"Zn\", \"Ga\", \"Ge\", \"As\", \"Se\", \"Br\", \"Kr\",\n",
    "                         \"Rb\", \"Sr\", \"Y\", \"Zr\", \"Nb\", \"Mo\", \"Tc\", \"Ru\", \"Rh\", \"Pd\", \"Ag\", \"Cd\", \"In\", \"Sn\", \"Sb\", \"Te\", \"I\", \"Xe\",\n",
    "                         \"Cs\", \"Ba\", \"La\",\n",
    "                         \"Ce\", \"Pr\", \"Nd\", \"Pm\", \"Sm\", \"Eu\", \"Gd\", \"Tb\", \"Dy\", \"Ho\", \"Er\", \"Tm\", \"Yb\", \"Lu\",\n",
    "                                           \"Hf\", \"Ta\", \"W\", \"Re\", \"Os\", \"Ir\", \"Pt\", \"Au\", \"Hg\", \"Tl\", \"Pb\", \"Bi\", \"Po\", \"At\", \"Rn\",\n",
    "                         \"Fr\", \"Ra\", \"Ac\", \n",
    "                         \"Th\", \"Pa\", \"U\", \"Np\", \"Pu\", \"Am\"])\n",
    "\n",
    "\n",
    "\n",
    "# xraylib uses keV\n",
    "fl_K = np.array([xlib.KA1_LINE, xlib.KA2_LINE, xlib.KA3_LINE, xlib.KB1_LINE, xlib.KB2_LINE,\n",
    "                 xlib.KB3_LINE, xlib.KB4_LINE, xlib.KB5_LINE])\n",
    "\n",
    "fl_L = np.array([xlib.LA1_LINE, xlib.LA2_LINE, xlib.LB1_LINE, xlib.LB2_LINE, xlib.LB3_LINE,\n",
    "                 xlib.LB4_LINE, xlib.LB5_LINE, xlib.LB6_LINE, xlib.LB7_LINE, xlib.LB9_LINE,\n",
    "                 xlib.LB10_LINE, xlib.LB15_LINE, xlib.LB17_LINE])\n",
    "\n",
    "fl_M = np.array([xlib.MA1_LINE, xlib.MA2_LINE, xlib.MB_LINE])\n",
    "\n",
    "fl_K_str = [\"Ka1\", \"Ka2\", \"Ka3\", \"Kb1\", \"Kb2\", \"Kb3\", \"Kb4\", \"Kb5\"]\n",
    "fl_L_str = [\"La1\", \"La2\", \"Lb1\", \"Lb2\", \"Lb3\", \"Lb4\",\"Lb5\", \"Lb6\",\n",
    "             \"Lb7\", \"Lb9\", \"Lb10\", \"Lb15\", \"Lb17\"]\n",
    "fl_Ma_str = [\"Ma1\", \"Ma2\", \"Mb\"]\n",
    "\n",
    "fl_line_groups = np.array([\"K\", \"L\", \"M\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attenuation(src_path, theta_st, theta_end, n_theta, sample_size_n,\n",
    "                sample_size_cm, this_aN_dic, probe_energy, padding=True):\n",
    "    \"\"\"\n",
    "    Calculate the attenuation ratio of the incident beam before the beam travels to a certain voxel.\n",
    "    Assuming that the x-ray probe goes along the direction of axis=1 of the sample array.\n",
    "    Calculate the transmission ratio at the exit of the sample.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    src_path: string\n",
    "        the path of the elemental map\n",
    "        \n",
    "    theta_st: float\n",
    "        The initial angle of the sample\n",
    "        \n",
    "    theta_end: float\n",
    "        The final angle of the sample\n",
    "    \n",
    "    sample_size_n: int scalar\n",
    "        sample size in number of pixles on one side, assuing a square sample of N x N pixels\n",
    "    \n",
    "    sample_size_cm: scalar\n",
    "        sample size in cm\n",
    "    \n",
    "    this_aN_dic: dictionary\n",
    "        a dictionary of items with key = element symbol (string), and value = atomic number\n",
    "        e.g. this_aN_dic = {\"C\":6, \"O\": 8}\n",
    "        \n",
    "    Returns: 2 ndarrays\n",
    "    -------\n",
    "        The 1st array is the attenuation ratio of the incident beam before the beam \n",
    "        travels to a certain voxel. Assuming that the x-ray probe goes along the direction\n",
    "        of axis=1 of the sample array.\n",
    "        dimension of the 1st returned array is (n_theta, sample_size_n, sample_size_n)\n",
    "        [note: sample_size may not be the same as the input argument because of padding]\n",
    "              \n",
    "        The 2nd array is the transmission ratio of the incident beam at the exit of \n",
    "        the sample.\n",
    "        dimension of the 2st returned array is (n_theta, sample_size_n)\n",
    "        [note: sample_size may not be the same as the input argument because of padding]\n",
    "    \"\"\"\n",
    "    element_ls = np.array(list(this_aN_dic.keys()))\n",
    "    aN_ls = np.array(list(this_aN_dic.values()))\n",
    "    \n",
    "    probe_attCS_ls = xlib_np.CS_Total(aN_ls, probe_energy).flatten()\n",
    "    probe_attCS_dic = dict(zip(element_ls, probe_attCS_ls))\n",
    "    \n",
    "    theta_ls = - np.linspace(theta_st, theta_end, n_theta)\n",
    "    \n",
    "    if padding is True:\n",
    "        padding_width = int(np.ceil(0.5 * (np.sqrt(2)-1) * sample_size_n))\n",
    "        sample_size_n = sample_size_n + 2 * padding_width\n",
    "        att_exponent_acc_map = np.zeros((len(theta_ls), sample_size_n, sample_size_n + 1))\n",
    "        for i, theta in enumerate(theta_ls):\n",
    "            for j, element in enumerate(element_ls):\n",
    "                concentration_map_fname = os.path.join(src_path, element + '_map.tiff')\n",
    "                concentration_map = dxchange.reader.read_tiff(concentration_map_fname)\n",
    "                concentration_map = np.pad(concentration_map, (padding_width, padding_width), mode=\"constant\", constant_values=(0,0))\n",
    "                concentration_map_rot = sp_rotate(concentration_map, theta, reshape=False, order=1)\n",
    "                lac_single = concentration_map_rot * probe_attCS_dic[element]\n",
    "                lac_acc = np.cumsum(lac_single, axis=1)\n",
    "                lac_acc = np.insert(lac_acc, 0, np.zeros(concentration_map.shape[0]), axis=1)\n",
    "                att_exponent_acc = lac_acc * (sample_size_cm / (sample_size_n - 2 * padding_width))\n",
    "                att_exponent_acc_map[i,:,:] += att_exponent_acc \n",
    "    else:\n",
    "        att_exponent_acc_map = np.zeros((len(theta_ls), sample_size_n, sample_size_n+1))\n",
    "        for i, theta in enumerate(theta_ls):\n",
    "            for j, element in enumerate(element_ls):\n",
    "                concentration_map_fname = os.path.join(src_path, element + '_map.tiff')\n",
    "                concentration_map = dxchange.reader.read_tiff(concentration_map_fname)\n",
    "                concentration_map_rot = sp_rotate(concentration_map, theta, reshape=False, order=1)\n",
    "                lac_single = concentration_map_rot * probe_attCS_dic[element]\n",
    "                lac_acc = np.cumsum(lac_single, axis=1)\n",
    "                lac_acc = np.insert(lac_acc, 0, np.zeros(concentration_map.shape[0]), axis=1)\n",
    "                att_exponent_acc = lac_acc * (sample_size_cm / sample_size_n)\n",
    "                att_exponent_acc_map[i,:,:] += att_exponent_acc   \n",
    "                \n",
    "    attenuation_map_flat = np.exp(-(att_exponent_acc_map[:,:,:-1].reshape(n_theta, sample_size_n * sample_size_n)))\n",
    "    transmission = np.exp(-att_exponent_acc_map[:,:,-1])\n",
    "    return attenuation_map_flat, transmission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MakeFLlinesDictionary(this_aN_dic, probe_energy,\n",
    "                          sample_size_n, sample_size_cm,\n",
    "                          fl_line_groups = np.array([\"K\", \"L\", \"M\"]), fl_K = fl_K, fl_L = fl_L, fl_M = fl_M,\n",
    "                          group_lines = True):\n",
    "    \"\"\"   \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    this_aN_dic: dictionary\n",
    "        a dictionary of items with key = element symbol (string), and value = atomic number\n",
    "        e.g. this_aN_dic = {\"C\":6, \"O\": 8}\n",
    "        \n",
    "    probe_energy : ndarray\n",
    "        This array is an array with only 1 element. The element is the keV energy of the incident beam.\n",
    "        \n",
    "    sample_size_n: int scalar\n",
    "        sample size in number of pixles on one side, assuing a square sample of N x N pixels\n",
    "        \n",
    "    sample_size_cm: scalar\n",
    "        sample size in cm\n",
    "        \n",
    "    fl_line_groups : ndarray, optional\n",
    "        DESCRIPTION. The default is np.array([\"K\", \"L\", \"M\"]).\n",
    "        \n",
    "    fl_K : ndarray, optional\n",
    "        The default is fl_K, an array of sub-lines of K line with the required format by xraylib.\n",
    "        \n",
    "    fl_L : ndarray, optional\n",
    "        The default is fl_L, an array of sub-lines of L line with the required format by xraylib.\n",
    "        \n",
    "    fl_M : ndarray, optional\n",
    "        The default is fl_M, an array of sub-lines of M line with the required format by xraylib.\n",
    "        \n",
    "    group_lines : boolean, optional\n",
    "        Whether treating all K (or L, M) sub-lines as a single line. The default is True.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    FL_all_elements_dic : dictionary\n",
    "        The dictionary has 3 items. \n",
    "        1st item \n",
    "        key: \"(element_name, Line)\"\n",
    "        value: an ndarray of ndarrays of 2 elements(type: string), [element symbol, line group]\n",
    "        e.g. [['C', 'K'], ['O', 'K'], ['Si', 'K'], ['Si', 'L']]\n",
    "        \n",
    "        2nd item\n",
    "        key: \"fl_energy\"\n",
    "        value: float, Fluorescence energy in keV for each line of all element\n",
    "        \n",
    "        3rd item: \"detected_fl_unit_concentration\"\n",
    "        key: fluorescence yield assuming a unit concentration [1 g/cm^3 ]\n",
    "    \"\"\"\n",
    "    \n",
    "    element_ls = np.array(list(this_aN_dic.keys()))\n",
    "    aN_ls = np.array(list(this_aN_dic.values()))\n",
    "\n",
    "    n_line_group = len(fl_line_groups)\n",
    "    FL_all_elements_dic = {\"element_Line\": [], \"fl_energy\": np.array([]), \"detected_fl_unit_concentration\": np.array([])}\n",
    "    voxel_size = sample_size_cm/sample_size_n\n",
    "\n",
    "    fl_cs_K = xlib_np.CS_FluorLine_Kissel_Cascade(aN_ls, fl_K, probe_energy)\n",
    "    fl_cs_L = xlib_np.CS_FluorLine_Kissel_Cascade(aN_ls, fl_L, probe_energy)\n",
    "    fl_cs_M = xlib_np.CS_FluorLine_Kissel_Cascade(aN_ls, fl_M, probe_energy)\n",
    "    \n",
    "    # Remove the extra dimension with only 1 element\n",
    "    fl_cs_K = np.reshape(fl_cs_K, (fl_cs_K.shape[:-1]))\n",
    "    fl_cs_L = np.reshape(fl_cs_L, (fl_cs_L.shape[:-1]))\n",
    "    fl_cs_M = np.reshape(fl_cs_M, (fl_cs_M.shape[:-1]))\n",
    "\n",
    "\n",
    "    fl_energy_K = xlib_np.LineEnergy(aN_ls, fl_K)\n",
    "    fl_energy_L = xlib_np.LineEnergy(aN_ls, fl_L)\n",
    "    fl_energy_M = xlib_np.LineEnergy(aN_ls, fl_M)\n",
    "    \n",
    "    FL_all_elements_dic = {\"(element_name, Line)\": [], \"fl_energy\": np.array([]), \"detected_fl_unit_concentration\": np.array([])}\n",
    "    if group_lines == True:\n",
    "        fl_energy_group = np.zeros((len(element_ls),n_line_group))\n",
    "        fl_cs_group = np.zeros((len(element_ls),n_line_group))\n",
    "        for i, element_name in enumerate(element_ls): \n",
    "        \n",
    "            if np.sum(fl_energy_K[i] != 0):\n",
    "                fl_energy_group[i,0] = np.average(fl_energy_K[i], weights=fl_cs_K[i]) \n",
    "                fl_cs_group[i,0] = np.sum(fl_cs_K[i])\n",
    "            else:\n",
    "                fl_energy_group[i,0] = 0\n",
    "                fl_cs_group[i,0] = 0\n",
    "        \n",
    "            if np.sum(fl_energy_L[i] != 0):\n",
    "                fl_energy_group[i,1] = np.average(fl_energy_L[i], weights=fl_cs_L[i]) \n",
    "                fl_cs_group[i,1] = np.sum(fl_cs_L[i])\n",
    "            else:\n",
    "                fl_energy_group[i,1] = 0\n",
    "                fl_cs_group[i,1] = 0\n",
    "\n",
    "            if np.sum(fl_energy_M[i] != 0):\n",
    "                fl_energy_group[i,2] = np.average(fl_energy_M[i], weights=fl_cs_M[i]) \n",
    "                fl_cs_group[i,2] = np.sum(fl_cs_M[i])\n",
    "            else:\n",
    "                fl_energy_group[i,2] = 0\n",
    "                fl_cs_group[i,2] = 0\n",
    "\n",
    "            element_Line = fl_line_groups[fl_energy_group[i]!= 0]\n",
    "            element_Line = [[element_name, element_Line[j]] for j in range(len(element_Line))]\n",
    "            for k in range(len(element_Line)):\n",
    "                FL_all_elements_dic[\"(element_name, Line)\"].append(element_Line[k])     \n",
    "        \n",
    "            Line_energy = fl_energy_group[i][fl_energy_group[i]!=0]\n",
    "            FL_all_elements_dic[\"fl_energy\"] = np.append(FL_all_elements_dic[\"fl_energy\"], Line_energy)\n",
    "        \n",
    "            fl_unit_con = fl_cs_group[i][fl_energy_group[i]!=0] * voxel_size\n",
    "            FL_all_elements_dic[\"detected_fl_unit_concentration\"] = np.append(FL_all_elements_dic[\"detected_fl_unit_concentration\"], fl_unit_con)\n",
    "            \n",
    "        FL_all_elements_dic[\"(element_name, Line)\"] = np.array(FL_all_elements_dic[\"(element_name, Line)\"])     \n",
    "    return FL_all_elements_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fl_signal_from_each_voxel(src_path, theta_st, theta_end, n_theta, sample_size_n, sample_size_cm, this_aN_dic, probe_energy, padding=True):\n",
    "    \n",
    "    element_ls = np.array(list(this_aN_dic.keys()))\n",
    "    theta_ls = - np.linspace(theta_st, theta_end, n_theta)\n",
    "    fl_all_lines_dic = MakeFLlinesDictionary(this_aN_dic, probe_energy,\n",
    "                          sample_size_n, sample_size_cm,\n",
    "                          fl_line_groups = np.array([\"K\", \"L\", \"M\"]), fl_K = fl_K, fl_L = fl_L, fl_M = fl_M,\n",
    "                          group_lines = True)\n",
    "    \n",
    "    if padding is True:\n",
    "        padding_width = int(np.ceil(0.5 * (np.sqrt(2)-1) * sample_size_n))\n",
    "        sample_size_n = sample_size_n + 2 * padding_width      \n",
    "        fl_map_tot = np.zeros((n_theta, sample_size_n * sample_size_n, len(fl_all_lines_dic[\"(element_name, Line)\"])))\n",
    "        for i, theta in enumerate(theta_ls):\n",
    "            line_idx = 0\n",
    "            for j, element in enumerate(element_ls):\n",
    "                concentration_map_fname = os.path.join(src_path, element + '_map.tiff')\n",
    "                concentration_map = dxchange.reader.read_tiff(concentration_map_fname)\n",
    "                concentration_map = np.pad(concentration_map, (padding_width, padding_width), mode=\"constant\", constant_values=(0,0))\n",
    "                concentration_map_rot = sp_rotate(concentration_map, theta, reshape=False, order=1)\n",
    "                concentration_map_rot_flat = concentration_map_rot.flatten()\n",
    "                fl_unit = fl_all_lines_dic[\"detected_fl_unit_concentration\"][fl_all_lines_dic[\"(element_name, Line)\"][:,0] == element]\n",
    "            \n",
    "                ## FL signal over the current elemental lines for each voxel\n",
    "                fl_map = np.array([concentration_map_rot_flat * fl_unit_single_line for fl_unit_single_line in fl_unit])\n",
    "                fl_map = np.transpose(fl_map)\n",
    "            \n",
    "                fl_map_tot[i,:,line_idx:line_idx + fl_map.shape[1]] = fl_map\n",
    "                line_idx = line_idx + len(fl_unit)\n",
    "    return fl_map_tot  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trace_beam_yint(x1, y1, xd, yd, sample_x_edge):\n",
    "    m = (yd - y1)/(xd - x1)\n",
    "    y_int = m * (sample_x_edge - x1) + y1\n",
    "    return m, y_int\n",
    "\n",
    "def trace_beam_xint(x1, y1, xd, yd, sample_y_edge):\n",
    "    if yd == y1:\n",
    "        m = 0\n",
    "        x_int = np.array([])\n",
    "    else:\n",
    "        m = (yd - y1)/(xd - x1)\n",
    "        x_int = (sample_y_edge - y1)/m + x1\n",
    "    return m, x_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersecting_length_fl_detectorlet(det_size_n, det_size_cm, det_from_sample_cm, sample_size_n, sample_size_cm, padding=True):\n",
    "    \n",
    "    voxel_size_cm = sample_size_cm/sample_size_n\n",
    "    \n",
    "    if padding is True:\n",
    "        padding_width = int(np.ceil(0.5 * (np.sqrt(2)-1) * sample_size_n))\n",
    "        sample_size_n = sample_size_n + 2 * padding_width\n",
    "        x1, y1 = np.indices((sample_size_n, sample_size_n))\n",
    "        \n",
    "        ## x index of the location of the XRF detector\n",
    "        det_axis_0_idx = (sample_size_n - padding_width) + np.ceil(det_from_sample_cm/voxel_size_cm) + 0.5\n",
    "        det_axis_0_idx_ls = np.full(det_size_n, det_axis_0_idx)\n",
    "\n",
    "    else:\n",
    "        x1, y1 = np.indices((sample_size_n, sample_size_n))\n",
    "        det_axis_0_idx = sample_size_n + np.ceil(det_from_sample_cm/voxel_size_cm) + 0.5\n",
    "        det_axis_0_idx_ls = np.full(det_size_n, det_axis_0_idx)\n",
    "   \n",
    "    ## y index of the location of the XRF detector\n",
    "    det_axis_1_idx_ls = np.linspace(np.ceil(sample_size_n/2) - det_size_n, \n",
    "                                      np.ceil(sample_size_n/2) + det_size_n, det_size_n) + 0.5\n",
    "    \n",
    "\n",
    "    ## biding x-index and y-index array into [(x1,y1), (x2,y2), ..., (x_Ndet, y_Ndet)]\n",
    "    det_pos_ls = np.array(list(zip(det_axis_0_idx_ls, det_axis_1_idx_ls)))\n",
    "    \n",
    "    ## define sample edges: \n",
    "    ## sample_x_edge is the edge that is closer to the XRF detector\n",
    "    ## sample_y_edge has two components representing the left and the right edge\n",
    "    sample_x_edge = sample_size_n\n",
    "    sample_y_edge = np.array([0, sample_size_n]) \n",
    "      \n",
    "    ## define index position of center of the source voxel (x1, y1), note that it's shifted by 0.5 to represent the center\n",
    "    x1, y1 = x1 + 0.5, y1 + 0.5\n",
    "    voxel_pos_ls = np.dstack((x1, y1))\n",
    "\n",
    "    ## make voxel_pos_ls 1D array for looping: voxel_pos_ls_flat\n",
    "    voxel_pos_ls_flat =  np.reshape(voxel_pos_ls, (1, voxel_pos_ls.shape[0] * voxel_pos_ls.shape[1], 2))[0]\n",
    "\n",
    "    P = np.zeros((det_size_n, sample_size_n * sample_size_n, sample_size_n * sample_size_n))\n",
    "    for i, det_pos in enumerate(det_pos_ls):\n",
    "        for j, v in enumerate(voxel_pos_ls_flat):\n",
    "            # find x-value when the beam passes the sample WITHOUT intersecting the sample_y_edges(left & right), namely the beam is parallel with the y edge of the sample. \n",
    "            # find x-value when the beam passes through sample_y_edges(left & right), the one with larger x is the intersection with lower edge\n",
    "            if v[1] == det_pos[1]:\n",
    "                xint = sample_size_n\n",
    "            else:\n",
    "                xint = np.max(trace_beam_xint(v[0], v[1], det_pos[0], det_pos[1], sample_y_edge)[1])\n",
    "            xint_sample = np.clip(xint, 0, sample_size_n)\n",
    "        \n",
    "            # find y-value when the beam passes through sample_x_edge(bottom)\n",
    "            m = trace_beam_yint(v[0], v[1], det_pos[0], det_pos[1], sample_x_edge)[0]\n",
    "            yint = trace_beam_yint(v[0], v[1], det_pos[0], det_pos[1], sample_x_edge)[1]\n",
    "            yint_sample = np.clip(yint, 0, sample_size_n)\n",
    "    \n",
    "               \n",
    "            # when the beam intersects with a voxel, it either intersects with the x boundary or y boundary of the voxel\n",
    "            # find the x,y-value of the boundary except the ones on the sample edge\n",
    "            if np.floor(xint_sample) != np.floor(v[0]):\n",
    "                x_edge_ls = np.linspace(np.ceil(xint_sample)-1, np.ceil(v[0]), int(np.abs(np.ceil(xint_sample) - np.ceil(v[0]))))\n",
    "            else: \n",
    "                x_edge_ls = np.array([])\n",
    "            \n",
    "        \n",
    "            if np.floor(yint_sample) != np.floor(v[1]):            \n",
    "                if m < 0:\n",
    "                    y_edge_ls = np.linspace(np.floor(yint_sample)+1, np.floor(v[1]), int(np.abs(np.floor(yint_sample)+1 - np.floor(v[1]))) + 1)            \n",
    "           \n",
    "                if m > 0:\n",
    "                    y_edge_ls = np.linspace(np.ceil(yint_sample)-1, np.ceil(v[1]), int(np.abs(np.ceil(yint_sample) - np.ceil(v[1]))))\n",
    "            else:\n",
    "                y_edge_ls = np.array([])\n",
    "        \n",
    "        \n",
    "            # find all intersections (except the initial intersection): \n",
    "            # 1. find y-value of intersection given x_edge_ls\n",
    "            # 2. find x-value of intersection given y_edge_ls\n",
    "            y_int_x_edge_ls = trace_beam_yint(v[0], v[1], det_pos[0], det_pos[1], x_edge_ls)[1] #solve y intersections given x edge\n",
    "            x_int_y_edge_ls = trace_beam_xint(v[0], v[1], det_pos[0], det_pos[1], y_edge_ls)[1] #solve x intersections given y edge\n",
    "        \n",
    "            # compile the x,y coordinates of the intersection: (x,y) = (x_edge_ls, y_int_x_edge_ls) and (x_int_y_edge_ls,y_edge_ls)\n",
    "            int_x_edge_ls = np.dstack((x_edge_ls,y_int_x_edge_ls))[0]\n",
    "            int_y_edge_ls = np.dstack((x_int_y_edge_ls,y_edge_ls))[0]\n",
    "\n",
    "            # sort them using the x coordinate\n",
    "            int_ls = np.concatenate((int_x_edge_ls, int_y_edge_ls))\n",
    "            int_ls = np.vstack((np.array([xint_sample, yint_sample]), int_ls))\n",
    "            int_ls = int_ls[np.argsort(int_ls[:,0])]\n",
    "        \n",
    "            # calculate the intersecting length in the intersecting voxels\n",
    "            int_length = np.sqrt(np.diff(int_ls[:,0])**2 + np.diff(int_ls[:,1])**2) \n",
    "            # just in case that we count some intersections twice, delete the duplicates\n",
    "            idx_duplicate = np.array(np.where(int_length==0)).flatten()\n",
    "            int_ls = np.delete(int_ls, idx_duplicate, 0)\n",
    "            int_length = np.delete(int_length, idx_duplicate) \n",
    "        \n",
    "            # determine the indices of the intersecting voxels according to the intersecting x,y-coordinates\n",
    "            int_ls_shift = np.zeros((int_ls.shape))\n",
    "            int_ls_shift[1:] = int_ls[:-1]\n",
    "            int_idx = np.floor((int_ls_shift + int_ls_shift)/2)[1:]        \n",
    "            int_idx = (int_idx[:,0].astype('int'), int_idx[:,1].astype('int'))\n",
    "        \n",
    "            # construct the int_length_map, and scale the intersecting length based on the voxel size\n",
    "            int_length_map = np.zeros((sample_size_n, sample_size_n))\n",
    "            int_length_map[int_idx] = int_length * voxel_size_cm  \n",
    "         \n",
    "            P[i, j, :] = int_length_map.flatten()\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_absorption_att_ratio_single_theta(src_path, det_size_n, det_size_cm, det_from_sample_cm, sample_size_n, sample_size_cm, \n",
    "                                       this_aN_dic, probe_energy, theta, padding=True):\n",
    "    \n",
    "    aN_ls = np.array(list(this_aN_dic.values()))\n",
    "    element_ls = np.array(list(this_aN_dic.keys()))    \n",
    "    \n",
    "    P = intersecting_length_fl_detectorlet(det_size_n, det_size_cm, det_from_sample_cm, sample_size_n, sample_size_cm, padding=True)\n",
    "    fl_all_lines_dic = MakeFLlinesDictionary(this_aN_dic, probe_energy,\n",
    "                          sample_size_n, sample_size_cm,\n",
    "                          fl_line_groups = np.array([\"K\", \"L\", \"M\"]), fl_K = fl_K, fl_L = fl_L, fl_M = fl_M,\n",
    "                          group_lines = True)   \n",
    "    \n",
    "    # generate an arrary of total attenuation cross section with the dimension: (n_element, n_elemental_lines)\n",
    "    # The component in the array represents the total attenuation cross section at some line energy in some element (with unitary concentration)\n",
    "    FL_line_attCS_ls = xlib_np.CS_Total(aN_ls, fl_all_lines_dic[\"fl_energy\"])\n",
    "    \n",
    "    if padding is True:\n",
    "        padding_width = int(np.ceil(0.5 * (np.sqrt(2)-1) * sample_size_n))\n",
    "        sample_size_n = sample_size_n + 2 * padding_width\n",
    "    \n",
    "        SA_ij = np.zeros((sample_size_n * sample_size_n, len(fl_all_lines_dic[\"(element_name, Line)\"])))\n",
    "        for j in tqdm(np.arange(sample_size_n * sample_size_n)):       \n",
    "            att_exponent_elemental_sum_temp = np.zeros((len(element_ls), det_size_n, len(fl_all_lines_dic[\"(element_name, Line)\"])))\n",
    "            for k, element in enumerate(element_ls):\n",
    "                concentration_map_fname = os.path.join(src_path, element + '_map.tiff')\n",
    "                concentration_map = dxchange.reader.read_tiff(concentration_map_fname)\n",
    "                concentration_map = np.pad(concentration_map, (padding_width, padding_width), mode=\"constant\", constant_values=(0,0))\n",
    "                concentration_map_rot = sp_rotate(concentration_map, theta, reshape=False, order=1)\n",
    "                ## flattened concentration_map after rotation: (sample_size_n * sample_size_n)\n",
    "                concentration_map_rot_flat = concentration_map_rot.flatten()\n",
    "            \n",
    "                ## llinear attenuation coefficient for each fl-line at each voxel: (sample_size * sample_size, len(fl_lines_all[\"(element_name, Line)\"]))\n",
    "                lac = np.array([FL_line_attCS * concentration_map_rot_flat for FL_line_attCS in FL_line_attCS_ls[k]])\n",
    "                lac = np.transpose(lac)\n",
    "            \n",
    "                ## att_exponent = [(intersecting_length_path1 * lac), (intersecting_length_path2 * lac), ..., (intersecting_length_path5 * lac)]:\n",
    "                ## att_exponent (for each fl-line, at each_voxel, for each beam path): (n_det, sample_size * sample_size, len(fl_lines_all[\"(element_name, Line)\"]))\n",
    "                att_exponent = np.array([P[m,j,:][:,np.newaxis] * lac for m in range(det_size_n)])\n",
    "            \n",
    "                ## att_exponent summing over voxels (for each line, for each beam path): (det_size_n, n_elemental_line)\n",
    "                att_exponent_voxel_sum = np.sum(att_exponent, axis=1)\n",
    "\n",
    "                ## filling att_exponent_voxel_sum to att_exponent_elemental_sum for each element\n",
    "                att_exponent_elemental_sum_temp[k, :, :] = att_exponent_voxel_sum\n",
    "        \n",
    "            ## summing over the attenation exponent contributed by each element\n",
    "            att_exponent_elemental_sum =  np.sum(att_exponent_elemental_sum_temp, axis=0) \n",
    "        \n",
    "        \n",
    "            ## calculate the attenuation caused by all elements\n",
    "            att = np.exp(- att_exponent_elemental_sum)\n",
    "            ## calculate the attenuation averaged all paths\n",
    "            att_path_ave = np.average(att, axis=0)\n",
    "            SA_ij[j,:] = att_path_ave\n",
    "        \n",
    "    return SA_ij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_absorption_att_ratio(n_thread, theta_st, theta_end, n_theta, src_path, det_size_n, det_size_cm, det_from_sample_cm, sample_size_n, sample_size_cm, \n",
    "                                       this_aN_dic, probe_energy, padding=True):\n",
    "    \n",
    "    pfunc = partial(self_absorption_att_ratio_single_theta, src_path, det_size_n, det_size_cm, det_from_sample_cm, sample_size_n, sample_size_cm, this_aN_dic, probe_energy, padding=True)\n",
    "    theta_ls = - np.linspace(theta_st, theta_end, n_theta) \n",
    "    with Pool(n_thread) as p:\n",
    "        SA = np.array(p.map(pfunc, theta_ls))    \n",
    "    return SA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_probe_before_attnuation_flat(sample_size_n, probe_cts, padding=True):\n",
    "    if padding is True:\n",
    "        padding_width = int(np.ceil(0.5 * (np.sqrt(2)-1) * sample_size_n))\n",
    "        sample_size_n = sample_size_n + 2 * padding_width      \n",
    "        probe_before_attnuation_flat = probe_cts * np.ones((sample_size_n * sample_size_n))\n",
    "    return probe_before_attnuation_flat\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_probe_after_attenuation_flat(src_path, theta_st, theta_end, n_theta, sample_size_n, sample_size_cm, this_aN_dic, probe_energy, probe_cts, padding=True):      \n",
    "    probe_before_attenuation_flat = create_probe_before_attnuation_flat(sample_size_n, probe_cts, padding)\n",
    "    att_ratio_map_flat = attenuation(src_path, theta_st, theta_end, n_theta, sample_size_n, sample_size_cm, this_aN_dic, probe_energy, padding)[0]\n",
    "    probe_after_attenuation_flat = probe_before_attenuation_flat * att_ratio_map_flat\n",
    "    return probe_after_attenuation_flat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_XRF_data(n_thread, theta_st, theta_end, n_theta, src_path, det_size_n, det_size_cm, det_from_sample_cm, sample_size_n,\n",
    "                    sample_size_cm, this_aN_dic, probe_cts, probe_energy, save_path, padding=True):      \n",
    "    \n",
    "    # (n_theta, sample_size_n * sample_size_n)\n",
    "    probe_after_attenuation = create_probe_after_attenuation_flat(src_path, theta_st, theta_end, n_theta, sample_size_n, sample_size_cm, this_aN_dic, probe_energy, probe_cts, padding)\n",
    "    \n",
    "    #(n_theta, sample_size_n * sample_size_n, n_elemental_line)\n",
    "    fl_ratio_map_tot = generate_fl_signal_from_each_voxel(src_path, theta_st, theta_end, n_theta, sample_size_n, sample_size_cm, this_aN_dic, probe_energy, padding)\n",
    "    \n",
    "    #elemental lines in cts generated at each voxel position (before going through self-absorption). dimension: (n_theta, sample_size * sample_size, n_elemental_line)\n",
    "    fl_signal_wo_SA = probe_after_attenuation[:,:,np.newaxis] * fl_ratio_map_tot\n",
    "    \n",
    "    #Calculate signal attenuation after self-absorption. dimension: (n_theta, sample_size * sample_size, n_elemental_line)\n",
    "    SA_att_ratio = self_absorption_att_ratio(n_thread, theta_st, theta_end, n_theta, src_path, det_size_n, det_size_cm, det_from_sample_cm, sample_size_n, sample_size_cm, \n",
    "                                       this_aN_dic, probe_energy, padding=True)\n",
    "       \n",
    "    #calculate fluorescence after self-absorption. dimension: (n_theta, len(smaple.shape[0]), n_elemental_line)\n",
    "    fl_signal_SA = fl_signal_wo_SA * SA_att_ratio\n",
    "    fl_signal_SA = np.sum(fl_signal_SA, axis=2)\n",
    "    \n",
    "    np.save(os.path.join(save_path, 'XRF_sample1.npy'), fl_signal_SA)\n",
    "    return fl_signal_SA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [00:03<00:00, 235.33it/s]\n",
      "100%|██████████| 900/900 [00:03<00:00, 232.81it/s]\n",
      "100%|██████████| 900/900 [00:03<00:00, 237.34it/s]\n",
      "100%|██████████| 900/900 [00:03<00:00, 236.01it/s]\n",
      "100%|██████████| 900/900 [00:03<00:00, 234.13it/s]\n",
      "100%|██████████| 900/900 [00:03<00:00, 233.97it/s]\n",
      "100%|██████████| 900/900 [00:03<00:00, 234.14it/s]\n",
      "100%|██████████| 900/900 [00:03<00:00, 234.63it/s]\n",
      "100%|██████████| 900/900 [00:03<00:00, 230.59it/s]\n",
      "100%|██████████| 900/900 [00:03<00:00, 230.68it/s]\n",
      "100%|██████████| 900/900 [00:03<00:00, 237.27it/s]\n",
      "100%|██████████| 900/900 [00:03<00:00, 235.73it/s]\n"
     ]
    }
   ],
   "source": [
    "params_2d_layer = {'n_thread': 2,\n",
    "                   'theta_st': 0, \n",
    "                   'theta_end': 180,\n",
    "                   'n_theta': 12, \n",
    "                   'src_path': '../data/sample1', \n",
    "                   'det_size_n': 5, \n",
    "                   'det_size_cm': 0.24, \n",
    "                   'det_from_sample_cm': 1.6,\n",
    "                   'sample_size_n': 20,\n",
    "                   'sample_size_cm': 0.1, \n",
    "                   'this_aN_dic': {\"C\": 6, \"O\": 8, \"Si\": 14, \"Ca\": 20, \"Fe\": 26},\n",
    "                   'probe_cts': 10E5, \n",
    "                   'probe_energy': np.array([20.0]),\n",
    "                   'save_path': '../data/test_data_elemental_lines'\n",
    "                  }\n",
    "\n",
    "params = params_2d_layer\n",
    "\n",
    "fl_signal_SA = create_XRF_data(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
